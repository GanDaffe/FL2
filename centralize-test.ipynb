{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:04:03.171053Z",
     "iopub.status.busy": "2025-05-26T05:04:03.170826Z",
     "iopub.status.idle": "2025-05-26T05:04:03.659080Z",
     "shell.execute_reply": "2025-05-26T05:04:03.658318Z",
     "shell.execute_reply.started": "2025-05-26T05:04:03.171031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:04:03.660157Z",
     "iopub.status.busy": "2025-05-26T05:04:03.659775Z",
     "iopub.status.idle": "2025-05-26T05:04:19.567027Z",
     "shell.execute_reply": "2025-05-26T05:04:19.566134Z",
     "shell.execute_reply.started": "2025-05-26T05:04:03.660132Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-3usuwhbiZUNWiZqUzRIJgnH1AjLCv0K\n",
      "To: /kaggle/working/Domain 1.feather\n",
      "100%|██████████████████████████████████████| 97.4M/97.4M [00:06<00:00, 14.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1-3usuwhbiZUNWiZqUzRIJgnH1AjLCv0K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:04:19.569523Z",
     "iopub.status.busy": "2025-05-26T05:04:19.569290Z",
     "iopub.status.idle": "2025-05-26T05:04:29.000709Z",
     "shell.execute_reply": "2025-05-26T05:04:28.999798Z",
     "shell.execute_reply.started": "2025-05-26T05:04:19.569500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1HvmlbHuwrmRUYJSyP8fKzq8dqKKKPMsv\n",
      "To: /kaggle/working/Domain 2.feather\n",
      "100%|██████████████████████████████████████| 84.1M/84.1M [00:02<00:00, 28.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1HvmlbHuwrmRUYJSyP8fKzq8dqKKKPMsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:04:29.002137Z",
     "iopub.status.busy": "2025-05-26T05:04:29.001818Z",
     "iopub.status.idle": "2025-05-26T05:04:39.139691Z",
     "shell.execute_reply": "2025-05-26T05:04:39.139057Z",
     "shell.execute_reply.started": "2025-05-26T05:04:29.002101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rzQx4mugpWQmJbAQzDCiEgqivSp2u9b-\n",
      "To: /kaggle/working/Domain 3.feather\n",
      "100%|██████████████████████████████████████| 65.4M/65.4M [00:02<00:00, 30.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1rzQx4mugpWQmJbAQzDCiEgqivSp2u9b-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:25:53.884958Z",
     "iopub.status.busy": "2025-05-26T05:25:53.884217Z",
     "iopub.status.idle": "2025-05-26T05:25:53.889303Z",
     "shell.execute_reply": "2025-05-26T05:25:53.888555Z",
     "shell.execute_reply.started": "2025-05-26T05:25:53.884906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from typing import List, Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:04:41.908865Z",
     "iopub.status.busy": "2025-05-26T05:04:41.908448Z",
     "iopub.status.idle": "2025-05-26T05:05:17.684712Z",
     "shell.execute_reply": "2025-05-26T05:05:17.684149Z",
     "shell.execute_reply.started": "2025-05-26T05:04:41.908837Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.0/540.0 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.7 which is incompatible.\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\n",
      "google-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 05:05:07.376225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748235907.567410      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748235907.625264      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "!pip install -q flwr[simulation]\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    Status,\n",
    "    NDArrays,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "import os\n",
    "\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "from functools import partial, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:26:44.148708Z",
     "iopub.status.busy": "2025-05-26T05:26:44.148382Z",
     "iopub.status.idle": "2025-05-26T05:26:44.169359Z",
     "shell.execute_reply": "2025-05-26T05:26:44.168626Z",
     "shell.execute_reply.started": "2025-05-26T05:26:44.148688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "def train(net, trainloader, criterion, optimizer, device, proximal_mu: float = None):\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    running_loss, running_corrects, tot = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    global_params = copy.deepcopy(net).parameters()\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if proximal_mu is not None:\n",
    "            proximal_term = sum((local - global_).norm(2)\n",
    "                                for local, global_ in zip(net.parameters(), global_params))\n",
    "            loss += (proximal_mu / 2) * proximal_term\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        tot += images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels).item()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    running_loss /= tot\n",
    "    accuracy = running_corrects / tot\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    TP = np.diag(cm)\n",
    "    FP = np.sum(cm, axis=0) - TP\n",
    "    FN = np.sum(cm, axis=1) - TP\n",
    "    TN = np.sum(cm) - (TP + FP + FN)\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    return running_loss, accuracy, precision, recall, f1, TP.sum(), FP.sum(), FN.sum(), TN.sum()\n",
    "\n",
    "\n",
    "\n",
    "def test(net, testloader, device):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    corrects, total_loss, tot = 0, 0.0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            corrects += torch.sum(preds == labels).item()\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            tot += images.size(0)\n",
    "\n",
    "    total_loss /= tot\n",
    "    accuracy = corrects / tot\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    TP = np.diag(cm)\n",
    "    FP = np.sum(cm, axis=0) - TP\n",
    "    FN = np.sum(cm, axis=1) - TP\n",
    "    TN = np.sum(cm) - (TP + FP + FN)\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    return total_loss, accuracy, precision, recall, f1, TP.sum(), FP.sum(), FN.sum(), TN.sum()\n",
    "\n",
    "\n",
    "def data_processing(df, NUM_FEATURES):\n",
    "   y_train = df['Label']\n",
    "   flow_id = df['flow_id']\n",
    "\n",
    "   df = df/255\n",
    "\n",
    "   X_train = df.drop(['Label', 'flow_id'], axis=1)\n",
    "   X_train = X_train.to_numpy()\n",
    "\n",
    "   X_train = X_train.reshape(-1, 20, NUM_FEATURES)\n",
    "   y_train = y_train.to_numpy()\n",
    "\n",
    "   y_train = y_train.reshape(-1,20)[:,-1]\n",
    "   return torch.from_numpy(X_train), torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:05:17.699786Z",
     "iopub.status.busy": "2025-05-26T05:05:17.699496Z",
     "iopub.status.idle": "2025-05-26T05:05:17.734488Z",
     "shell.execute_reply": "2025-05-26T05:05:17.733847Z",
     "shell.execute_reply.started": "2025-05-26T05:05:17.699759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BN_CNN(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channel,\n",
    "            out_channels=128,\n",
    "            kernel_size=5,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=128,\n",
    "            out_channels=64,\n",
    "            kernel_size=5,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=16)\n",
    "      \n",
    "        self.lin1 = nn.Linear(16 * 2 * 32, 256)\n",
    "        self.classification = nn.Linear(256, out_features=num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.pool(self.bn1(self.relu(self.conv2(self.relu(self.conv1(X))))))\n",
    "        X = self.pool(self.bn2(self.relu(self.conv4(self.relu(self.conv3(X))))))\n",
    "        X = self.pool(self.bn3(self.relu(self.conv6(self.relu(self.conv5(X))))))\n",
    "\n",
    "        X = torch.flatten(X, start_dim=1) \n",
    "        X = self.lin1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.dropout(X)\n",
    "        X = self.classification(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:05:17.736965Z",
     "iopub.status.busy": "2025-05-26T05:05:17.736596Z",
     "iopub.status.idle": "2025-05-26T05:05:17.750499Z",
     "shell.execute_reply": "2025-05-26T05:05:17.749808Z",
     "shell.execute_reply.started": "2025-05-26T05:05:17.736946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channel,\n",
    "            out_channels=128,\n",
    "            kernel_size=5,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=128,\n",
    "            out_channels=64,\n",
    "            kernel_size=5,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        self.lin1 = nn.Linear(16 * 2 * 32, 256)\n",
    "        self.classification = nn.Linear(256, out_features=num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.pool(self.relu(self.conv2(self.relu(self.conv1(X)))))\n",
    "        X = self.pool(self.relu(self.conv4(self.relu(self.conv3(X)))))\n",
    "        X = self.pool(self.relu(self.conv6(self.relu(self.conv5(X)))))\n",
    "\n",
    "        X = torch.flatten(X, start_dim=1)\n",
    "        X = self.lin1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.dropout(X)\n",
    "        X = self.classification(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:05:17.751509Z",
     "iopub.status.busy": "2025-05-26T05:05:17.751255Z",
     "iopub.status.idle": "2025-05-26T05:05:17.765217Z",
     "shell.execute_reply": "2025-05-26T05:05:17.764648Z",
     "shell.execute_reply.started": "2025-05-26T05:05:17.751486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_data, targets, transform=None):\n",
    "        # Ép kiểu float32 cho mỗi tensor\n",
    "        self.data = [input_data[i].unsqueeze(0).float() for i in range(input_data.size(0))]\n",
    "        self.targets = targets\n",
    "        self.classes = torch.unique(targets).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:05:17.766159Z",
     "iopub.status.busy": "2025-05-26T05:05:17.765899Z",
     "iopub.status.idle": "2025-05-26T05:05:19.059417Z",
     "shell.execute_reply": "2025-05-26T05:05:19.058699Z",
     "shell.execute_reply.started": "2025-05-26T05:05:17.766136Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3418</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>225</td>\n",
       "      <td>139</td>\n",
       "      <td>5</td>\n",
       "      <td>233</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>188</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>105</td>\n",
       "      <td>185</td>\n",
       "      <td>244</td>\n",
       "      <td>201</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3418</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3418</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3418</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>79</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3418</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>156</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124935</th>\n",
       "      <td>212962</td>\n",
       "      <td>144</td>\n",
       "      <td>239</td>\n",
       "      <td>122</td>\n",
       "      <td>158</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>164</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124936</th>\n",
       "      <td>212962</td>\n",
       "      <td>144</td>\n",
       "      <td>111</td>\n",
       "      <td>122</td>\n",
       "      <td>176</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>148</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124937</th>\n",
       "      <td>212962</td>\n",
       "      <td>144</td>\n",
       "      <td>111</td>\n",
       "      <td>122</td>\n",
       "      <td>166</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>110</td>\n",
       "      <td>164</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124938</th>\n",
       "      <td>212962</td>\n",
       "      <td>144</td>\n",
       "      <td>111</td>\n",
       "      <td>122</td>\n",
       "      <td>177</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>151</td>\n",
       "      <td>228</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124939</th>\n",
       "      <td>212962</td>\n",
       "      <td>144</td>\n",
       "      <td>111</td>\n",
       "      <td>122</td>\n",
       "      <td>165</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>106</td>\n",
       "      <td>228</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459720 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        flow_id    0    1    2    3    4    5    6    7    8  ...  247  248  \\\n",
       "7          3418   23    3    3    1   58  225  139    5  233  ...   77  188   \n",
       "6          3418   23    3    3    0  165   58   55   16  196  ...    0    0   \n",
       "5          3418   20    3    3    0    1    1   23    3    3  ...    0    0   \n",
       "4          3418   23    3    3    0   47  122   79   32  128  ...    0    0   \n",
       "3          3418   23    3    3    0  154   85   85  156   61  ...    0    0   \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "124935   212962  144  239  122  158   85   81   80  164   12  ...    0    0   \n",
       "124936   212962  144  111  122  176   85   81  148   36   12  ...    0    0   \n",
       "124937   212962  144  111  122  166   85   81  110  164   12  ...    0    0   \n",
       "124938   212962  144  111  122  177   85   81  151  228   12  ...    0    0   \n",
       "124939   212962  144  111  122  165   85   81  106  228   12  ...    0    0   \n",
       "\n",
       "        249  250  251  252  253  254  255  Label  \n",
       "7        75   60  105  185  244  201   71      0  \n",
       "6         0    0    0    0    0    0    0      0  \n",
       "5         0    0    0    0    0    0    0      0  \n",
       "4         0    0    0    0    0    0    0      0  \n",
       "3         0    0    0    0    0    0    0      0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...    ...  \n",
       "124935    0    0    0    0    0    0    0      2  \n",
       "124936    0    0    0    0    0    0    0      2  \n",
       "124937    0    0    0    0    0    0    0      2  \n",
       "124938    0    0    0    0    0    0    0      2  \n",
       "124939    0    0    0    0    0    0    0      2  \n",
       "\n",
       "[459720 rows x 258 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_data = pd.read_feather('/home/bkcs/Documents/Fair/FL2/data/Domain 1.feather')\n",
    "c2_data = pd.read_feather('/home/bkcs/Documents/Fair/FL2/data/Domain 2.feather')\n",
    "c3_data = pd.read_feather('/home/bkcs/Documents/Fair/FL2/data/Domain 3.feather')\n",
    "\n",
    "data_full = [c1_data, c2_data , c3_data]\n",
    "df_full = pd.concat(data_full)\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:24:27.920101Z",
     "iopub.status.busy": "2025-05-26T05:24:27.919735Z",
     "iopub.status.idle": "2025-05-26T05:24:29.135346Z",
     "shell.execute_reply": "2025-05-26T05:24:29.134536Z",
     "shell.execute_reply.started": "2025-05-26T05:24:27.920077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set to 42\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    print(f\"Seeds set to {seed_value}\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_STATE = 42\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "all_data = data_processing(df_full, 256)\n",
    "full_dataset = CustomDataset(all_data[0], all_data[1])\n",
    "\n",
    "trainset, testset = train_test_split(full_dataset, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, num_workers=4)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T05:29:16.088128Z",
     "iopub.status.busy": "2025-05-26T05:29:16.087449Z",
     "iopub.status.idle": "2025-05-26T05:32:01.028958Z",
     "shell.execute_reply": "2025-05-26T05:32:01.028077Z",
     "shell.execute_reply.started": "2025-05-26T05:29:16.088093Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.3660, Acc: 0.8557, Prec: 0.8476, Recall: 0.8422, F1: 0.8435\n",
      "Train TP: 15735, FP: 2653, FN: 2653, TN: 34123\n",
      "Test  Loss: 0.2083, Acc: 0.9234, Prec: 0.9193, Recall: 0.9194, F1: 0.9193\n",
      "Test  TP: 4246, FP: 352, FN: 352, TN: 8844\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/10\n",
      "Train Loss: 0.1899, Acc: 0.9295, Prec: 0.9249, Recall: 0.9227, F1: 0.9236\n",
      "Train TP: 17091, FP: 1297, FN: 1297, TN: 35479\n",
      "Test  Loss: 0.2159, Acc: 0.9200, Prec: 0.9179, Recall: 0.9216, F1: 0.9171\n",
      "Test  TP: 4230, FP: 368, FN: 368, TN: 8828\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/10\n",
      "Train Loss: 0.1459, Acc: 0.9484, Prec: 0.9456, Recall: 0.9432, F1: 0.9442\n",
      "Train TP: 17440, FP: 948, FN: 948, TN: 35828\n",
      "Test  Loss: 0.2109, Acc: 0.9291, Prec: 0.9282, Recall: 0.9318, F1: 0.9269\n",
      "Test  TP: 4272, FP: 326, FN: 326, TN: 8870\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/10\n",
      "Train Loss: 0.1166, Acc: 0.9621, Prec: 0.9605, Recall: 0.9580, F1: 0.9591\n",
      "Train TP: 17692, FP: 696, FN: 696, TN: 36080\n",
      "Test  Loss: 0.1333, Acc: 0.9528, Prec: 0.9499, Recall: 0.9528, F1: 0.9508\n",
      "Test  TP: 4381, FP: 217, FN: 217, TN: 8979\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0952, Acc: 0.9690, Prec: 0.9677, Recall: 0.9656, F1: 0.9666\n",
      "Train TP: 17818, FP: 570, FN: 570, TN: 36206\n",
      "Test  Loss: 0.1103, Acc: 0.9598, Prec: 0.9578, Recall: 0.9575, F1: 0.9576\n",
      "Test  TP: 4413, FP: 185, FN: 185, TN: 9011\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0810, Acc: 0.9741, Prec: 0.9732, Recall: 0.9711, F1: 0.9721\n",
      "Train TP: 17911, FP: 477, FN: 477, TN: 36299\n",
      "Test  Loss: 0.1075, Acc: 0.9617, Prec: 0.9595, Recall: 0.9602, F1: 0.9598\n",
      "Test  TP: 4422, FP: 176, FN: 176, TN: 9020\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0661, Acc: 0.9779, Prec: 0.9771, Recall: 0.9755, F1: 0.9763\n",
      "Train TP: 17982, FP: 406, FN: 406, TN: 36370\n",
      "Test  Loss: 0.1037, Acc: 0.9659, Prec: 0.9635, Recall: 0.9655, F1: 0.9643\n",
      "Test  TP: 4441, FP: 157, FN: 157, TN: 9039\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0505, Acc: 0.9847, Prec: 0.9845, Recall: 0.9827, F1: 0.9835\n",
      "Train TP: 18106, FP: 282, FN: 282, TN: 36494\n",
      "Test  Loss: 0.1613, Acc: 0.9428, Prec: 0.9406, Recall: 0.9442, F1: 0.9409\n",
      "Test  TP: 4335, FP: 263, FN: 263, TN: 8933\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0460, Acc: 0.9856, Prec: 0.9855, Recall: 0.9837, F1: 0.9845\n",
      "Train TP: 18123, FP: 265, FN: 265, TN: 36511\n",
      "Test  Loss: 0.1831, Acc: 0.9302, Prec: 0.9413, Recall: 0.9184, F1: 0.9236\n",
      "Test  TP: 4277, FP: 321, FN: 321, TN: 8875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0422, Acc: 0.9860, Prec: 0.9858, Recall: 0.9841, F1: 0.9849\n",
      "Train TP: 18130, FP: 258, FN: 258, TN: 36518\n",
      "Test  Loss: 0.1013, Acc: 0.9682, Prec: 0.9667, Recall: 0.9665, F1: 0.9666\n",
      "Test  TP: 4452, FP: 146, FN: 146, TN: 9050\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def training_loop(net, trainloader, testloader, device, epochs=10, proximal_mu=None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.003)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc, train_prec, train_recall, train_f1, TP, FP, FN, TN = train(\n",
    "            net, trainloader, criterion, optimizer, device, proximal_mu)\n",
    "\n",
    "        test_loss, test_acc, test_prec, test_recall, test_f1, TP_t, FP_t, FN_t, TN_t = test(\n",
    "            net, testloader, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Prec: {train_prec:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n",
    "        print(f\"Train TP: {TP}, FP: {FP}, FN: {FN}, TN: {TN}\")\n",
    "        print(f\"Test  Loss: {test_loss:.4f}, Acc: {test_acc:.4f}, Prec: {test_prec:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "        print(f\"Test  TP: {TP_t}, FP: {FP_t}, FN: {FN_t}, TN: {TN_t}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    \n",
    "model = BN_CNN(1,3).to(DEVICE)\n",
    "\n",
    "training_loop(model, trainloader, testloader, DEVICE, 10)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

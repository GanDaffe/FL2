{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:06.267097Z",
     "iopub.status.busy": "2025-05-24T10:15:06.266743Z",
     "iopub.status.idle": "2025-05-24T10:15:06.641287Z",
     "shell.execute_reply": "2025-05-24T10:15:06.640703Z",
     "shell.execute_reply.started": "2025-05-24T10:15:06.267047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:06.643371Z",
     "iopub.status.busy": "2025-05-24T10:15:06.642582Z",
     "iopub.status.idle": "2025-05-24T10:15:17.561159Z",
     "shell.execute_reply": "2025-05-24T10:15:17.559997Z",
     "shell.execute_reply.started": "2025-05-24T10:15:06.643349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!gdown --id 1-3usuwhbiZUNWiZqUzRIJgnH1AjLCv0K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:17.562490Z",
     "iopub.status.busy": "2025-05-24T10:15:17.562227Z",
     "iopub.status.idle": "2025-05-24T10:15:25.041840Z",
     "shell.execute_reply": "2025-05-24T10:15:25.041122Z",
     "shell.execute_reply.started": "2025-05-24T10:15:17.562464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!gdown --id 1HvmlbHuwrmRUYJSyP8fKzq8dqKKKPMsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:25.044488Z",
     "iopub.status.busy": "2025-05-24T10:15:25.044184Z",
     "iopub.status.idle": "2025-05-24T10:15:30.690996Z",
     "shell.execute_reply": "2025-05-24T10:15:30.690272Z",
     "shell.execute_reply.started": "2025-05-24T10:15:25.044462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!gdown --id 1rzQx4mugpWQmJbAQzDCiEgqivSp2u9b-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:58.537591Z",
     "iopub.status.busy": "2025-05-24T10:15:58.536982Z",
     "iopub.status.idle": "2025-05-24T10:15:58.541887Z",
     "shell.execute_reply": "2025-05-24T10:15:58.541222Z",
     "shell.execute_reply.started": "2025-05-24T10:15:58.537566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from typing import List, Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:34.969750Z",
     "iopub.status.busy": "2025-05-24T10:15:34.969355Z",
     "iopub.status.idle": "2025-05-24T10:15:46.528582Z",
     "shell.execute_reply": "2025-05-24T10:15:46.527944Z",
     "shell.execute_reply.started": "2025-05-24T10:15:34.969730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q flwr[simulation]\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    Status,\n",
    "    NDArrays,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "import os\n",
    "\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "from functools import partial, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:46.529721Z",
     "iopub.status.busy": "2025-05-24T10:15:46.529423Z",
     "iopub.status.idle": "2025-05-24T10:15:46.542667Z",
     "shell.execute_reply": "2025-05-24T10:15:46.541901Z",
     "shell.execute_reply.started": "2025-05-24T10:15:46.529697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "def train(net, trainloader, criterion, optimizer, device, proximal_mu: float = None):\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    running_loss, running_corrects, tot = 0.0, 0, 0\n",
    "\n",
    "    global_params = copy.deepcopy(net).parameters()\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if proximal_mu is not None:\n",
    "            proximal_term = sum((local - global_).norm(2)\n",
    "                                for local, global_ in zip(net.parameters(), global_params))\n",
    "            loss += (proximal_mu / 2) * proximal_term\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        tot += images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels).item()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    running_loss /= tot\n",
    "    accuracy = running_corrects / tot\n",
    "    \n",
    "    return running_loss, accuracy\n",
    "\n",
    "\n",
    "def test(net, testloader, device):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    corrects, total_loss, tot = 0, 0.0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            corrects += torch.sum(preds == labels).item()\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            tot += images.size(0)\n",
    "\n",
    "    total_loss /= tot\n",
    "    accuracy = corrects / tot\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    return total_loss, accuracy, precision, recall, f1\n",
    "\n",
    "def data_processing(df, NUM_FEATURES):\n",
    "   y_train = df['Label']\n",
    "   flow_id = df['flow_id']\n",
    "\n",
    "   df = df/255\n",
    "\n",
    "   X_train = df.drop(['Label', 'flow_id'], axis=1)\n",
    "   X_train = X_train.to_numpy()\n",
    "\n",
    "   X_train = X_train.reshape(-1, 20, NUM_FEATURES)\n",
    "   y_train = y_train.to_numpy()\n",
    "\n",
    "   y_train = y_train.reshape(-1,20)[:,-1]\n",
    "   return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:46.543695Z",
     "iopub.status.busy": "2025-05-24T10:15:46.543491Z",
     "iopub.status.idle": "2025-05-24T10:15:46.566981Z",
     "shell.execute_reply": "2025-05-24T10:15:46.566302Z",
     "shell.execute_reply.started": "2025-05-24T10:15:46.543666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BN_CNN(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channel,\n",
    "            out_channels=128,\n",
    "            kernel_size=5,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=128,\n",
    "            out_channels=64,\n",
    "            kernel_size=5,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=16)\n",
    "      \n",
    "        self.lin1 = nn.Linear(16 * 2 * 32, 256)\n",
    "        self.classification = nn.Linear(256, out_features=num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.pool(self.bn1(self.relu(self.conv2(self.relu(self.conv1(X))))))\n",
    "        X = self.pool(self.bn2(self.relu(self.conv4(self.relu(self.conv3(X))))))\n",
    "        X = self.pool(self.bn3(self.relu(self.conv6(self.relu(self.conv5(X))))))\n",
    "\n",
    "        X = torch.flatten(X, start_dim=1) \n",
    "        X = self.lin1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.dropout(X)\n",
    "        X = self.classification(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:46.567895Z",
     "iopub.status.busy": "2025-05-24T10:15:46.567685Z",
     "iopub.status.idle": "2025-05-24T10:15:46.581792Z",
     "shell.execute_reply": "2025-05-24T10:15:46.581049Z",
     "shell.execute_reply.started": "2025-05-24T10:15:46.567879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channel,\n",
    "            out_channels=128,\n",
    "            kernel_size=5,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=128,\n",
    "            out_channels=64,\n",
    "            kernel_size=5,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            padding='same')\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        self.lin1 = nn.Linear(16 * 2 * 32, 256)\n",
    "        self.classification = nn.Linear(256, out_features=num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.pool(self.relu(self.conv2(self.relu(self.conv1(X)))))\n",
    "        X = self.pool(self.relu(self.conv4(self.relu(self.conv3(X)))))\n",
    "        X = self.pool(self.relu(self.conv6(self.relu(self.conv5(X)))))\n",
    "\n",
    "        X = torch.flatten(X, start_dim=1)\n",
    "        X = self.lin1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.dropout(X)\n",
    "        X = self.classification(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:46.584164Z",
     "iopub.status.busy": "2025-05-24T10:15:46.583935Z",
     "iopub.status.idle": "2025-05-24T10:15:46.605879Z",
     "shell.execute_reply": "2025-05-24T10:15:46.605268Z",
     "shell.execute_reply.started": "2025-05-24T10:15:46.584148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from algorithm.import_lib import *\n",
    "\n",
    "class FedAvg(fl.server.strategy.Strategy):\n",
    "    def __init__(\n",
    "        self, exp_name, algo_name, num_rounds, num_clients, device,\n",
    "        decay_rate=0.995, fraction_fit=1.0, fraction_evaluate=1.0,\n",
    "        min_fit_clients=2, min_evaluate_clients=2, min_available_clients=2,\n",
    "        learning_rate=0.01, current_parameters=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.exp_name = exp_name\n",
    "        self.algo_name = algo_name\n",
    "        self.num_rounds = num_rounds\n",
    "        self.num_clients = num_clients\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_parameters = current_parameters\n",
    "        self.device = device\n",
    "        self.decay_rate = decay_rate\n",
    "        self.result = {\n",
    "            \"round\": [],\n",
    "            \"train_loss\": [],\n",
    "            \"train_accuracy\": [],\n",
    "            \"test_loss\": [],\n",
    "            \"test_accuracy\": [],\n",
    "            \"test_precision\": [],\n",
    "            \"test_recall\": [],\n",
    "            \"test_f1\": []\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"FedAvg\"\n",
    "\n",
    "    def initialize_parameters(self, client_manager):\n",
    "        return self.current_parameters\n",
    "\n",
    "    def configure_fit(self, server_round, parameters, client_manager):\n",
    "        sample_size, min_num_clients = self.num_fit_clients(client_manager.num_available())\n",
    "        clients = client_manager.sample(sample_size, min_num_clients)\n",
    "        config = {\"learning_rate\": self.learning_rate, \"device\": self.device}\n",
    "        self.learning_rate *= self.decay_rate\n",
    "        return [(client, FitIns(parameters, config)) for client in clients]\n",
    "\n",
    "    def aggregate_fit(self, server_round, results, failures):\n",
    "        self.current_parameters = ndarrays_to_parameters(\n",
    "            aggregate([(parameters_to_ndarrays(f.parameters), f.num_examples) for _, f in results])\n",
    "        )\n",
    "        examples = [f.num_examples for _, f in results]\n",
    "        total = sum(examples)\n",
    "\n",
    "        def weighted_avg(metric_name):\n",
    "            return sum(f.num_examples * f.metrics[metric_name] for _, f in results) / total\n",
    "\n",
    "        loss = weighted_avg(\"loss\")\n",
    "        acc = weighted_avg(\"accuracy\")\n",
    "\n",
    "        self.result[\"round\"].append(server_round)\n",
    "        self.result[\"train_loss\"].append(loss)\n",
    "        self.result[\"train_accuracy\"].append(acc)\n",
    "\n",
    "        print(f\"Train R{server_round}: loss={loss:.4f}, acc={acc:.4f}\")\n",
    "\n",
    "        return self.current_parameters, {}\n",
    "\n",
    "    def configure_evaluate(self, server_round, parameters, client_manager):\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(client_manager.num_available())\n",
    "        clients = client_manager.sample(sample_size, min_num_clients)\n",
    "        config = {\"device\": self.device}\n",
    "        return [(client, EvaluateIns(parameters, config)) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(self, server_round, results, failures):\n",
    "        examples = [r.num_examples for _, r in results]\n",
    "        total = sum(examples)\n",
    "\n",
    "        def weighted_avg(metric_name):\n",
    "            return sum(r.num_examples * r.metrics[metric_name] for _, r in results) / total\n",
    "\n",
    "        loss = sum(r.num_examples * r.loss for _, r in results) / total\n",
    "        acc = weighted_avg(\"accuracy\")\n",
    "        prec = weighted_avg(\"precision\")\n",
    "        rec = weighted_avg(\"recall\")\n",
    "        f1 = weighted_avg(\"f1\")\n",
    "\n",
    "        if server_round != 0:\n",
    "            self.result[\"test_loss\"].append(loss)\n",
    "            self.result[\"test_accuracy\"].append(acc)\n",
    "            self.result[\"test_precision\"].append(prec)\n",
    "            self.result[\"test_recall\"].append(rec)\n",
    "            self.result[\"test_f1\"].append(f1)\n",
    "\n",
    "        print(f\"Test R{server_round}: loss={loss:.4f}, acc={acc:.4f}, prec={prec:.4f}, recall={rec:.4f}, f1={f1:.4f}\")\n",
    "\n",
    "        if server_round == self.num_rounds:\n",
    "            pd.DataFrame(self.result).to_csv(f\"result/{self.algo_name}_{self.exp_name}.csv\", index=False)\n",
    "\n",
    "        return loss, {}\n",
    "\n",
    "    def evaluate(self, server_round, parameters):\n",
    "        return None\n",
    "\n",
    "    def num_fit_clients(self, num_available):\n",
    "        return max(int(num_available * self.fraction_fit), self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available):\n",
    "        return max(int(num_available * self.fraction_evaluate), self.min_evaluate_clients), self.min_available_clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:46.606749Z",
     "iopub.status.busy": "2025-05-24T10:15:46.606508Z",
     "iopub.status.idle": "2025-05-24T10:15:46.624572Z",
     "shell.execute_reply": "2025-05-24T10:15:46.623856Z",
     "shell.execute_reply.started": "2025-05-24T10:15:46.606724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from algorithm.import_lib import *\n",
    "\n",
    "class BaseClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader, criterion):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        optimizer = torch.optim.SGD(self.net.parameters(), lr=config[\"learning_rate\"])\n",
    "        loss, acc = train(self.net, self.trainloader, self.criterion, optimizer, device=config[\"device\"])\n",
    "        return self.get_parameters(config), len(self.trainloader.sampler), {\n",
    "            \"loss\": loss,\n",
    "            \"accuracy\": acc,\n",
    "            \"id\": self.cid\n",
    "        }\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, acc, prec, rec, f1 = test(self.net, self.valloader, config[\"device\"])\n",
    "        return loss, len(self.valloader.sampler), {\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1\": f1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:46.625456Z",
     "iopub.status.busy": "2025-05-24T10:15:46.625292Z",
     "iopub.status.idle": "2025-05-24T10:15:46.641176Z",
     "shell.execute_reply": "2025-05-24T10:15:46.640518Z",
     "shell.execute_reply.started": "2025-05-24T10:15:46.625443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_data, targets, transform=None):\n",
    "        self.data = [input_data[i].unsqueeze(0).float() for i in range(input_data.size(0))]\n",
    "        self.targets = targets\n",
    "        self.classes = torch.unique(targets).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:15:46.642086Z",
     "iopub.status.busy": "2025-05-24T10:15:46.641802Z",
     "iopub.status.idle": "2025-05-24T10:15:47.550863Z",
     "shell.execute_reply": "2025-05-24T10:15:47.550303Z",
     "shell.execute_reply.started": "2025-05-24T10:15:46.642043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "c1_data = pd.read_feather('/kaggle/working/Domain 1.feather')\n",
    "c2_data = pd.read_feather('/kaggle/working/Domain 2.feather')\n",
    "c3_data = pd.read_feather('/kaggle/working/Domain 3.feather')\n",
    "\n",
    "data_full = [c1_data, c2_data , c3_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:21:53.104491Z",
     "iopub.status.busy": "2025-05-24T10:21:53.103832Z",
     "iopub.status.idle": "2025-05-24T10:21:54.366906Z",
     "shell.execute_reply": "2025-05-24T10:21:54.366112Z",
     "shell.execute_reply.started": "2025-05-24T10:21:53.104464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    print(f\"Seeds set to {seed_value}\")\n",
    "\n",
    "def domain_partition(X, y, num_clients):\n",
    "    num_classes = np.unique(y).shape[0]\n",
    "    class_indices = [[] for _ in range(num_classes)]\n",
    "\n",
    "    for i, lab in enumerate(y):\n",
    "        class_indices[lab].append(i)\n",
    "\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        proportions = np.random.dirichlet(np.ones(num_clients) * 5)\n",
    "        indices = np.array(class_indices[c])\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        proportions = (np.cumsum(proportions) * len(indices)).astype(int)[:-1]\n",
    "        split_indices = np.split(indices, proportions)\n",
    "\n",
    "        for i, idx in enumerate(split_indices):\n",
    "            client_indices[i].extend(idx.tolist())\n",
    "\n",
    "    client_data = [(torch.from_numpy(X[client_idx]), torch.from_numpy(y[client_idx])) for client_idx in client_indices]\n",
    "\n",
    "    return client_data\n",
    "\n",
    "def get_clients_dataset(full_domain_data, num_domains, num_clients_per_domain):   \n",
    "    set_seed(42)\n",
    "    all_data = [] \n",
    "\n",
    "    for domain in full_domain_data:\n",
    "        all_data.append(data_processing(domain, 256))\n",
    "\n",
    "    domain_clients = []\n",
    "    for data, label in all_data:  \n",
    "        domain_clients.extend(domain_partition(data, label, num_clients_per_domain))\n",
    "\n",
    "    for i in range(len(domain_clients)):\n",
    "        domain_clients[i] = CustomDataset(domain_clients[i][0], domain_clients[i][1])\n",
    "    return domain_clients\n",
    "    \n",
    "\n",
    "NUM_DOMAINS = 3\n",
    "NUM_CLIENTS_PER_DOMAIN = 3\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_STATE = 42\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "clients_dataset = get_clients_dataset(data_full, NUM_DOMAINS, NUM_CLIENTS_PER_DOMAIN)\n",
    "\n",
    "train_set, validation_set = [], []\n",
    "\n",
    "for i in range(len(clients_dataset)):\n",
    "    train, val = train_test_split(clients_dataset[i], test_size=0.2, random_state=RANDOM_STATE)\n",
    "    train_set.append(train)\n",
    "    validation_set.append(val)\n",
    "\n",
    "trainloaders = [DataLoader(train_set[i], batch_size=BATCH_SIZE) for i in range(len(train_set))]\n",
    "valloaders = [DataLoader(validation_set[i], batch_size=BATCH_SIZE) for i in range(len(validation_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:21:54.811718Z",
     "iopub.status.busy": "2025-05-24T10:21:54.811208Z",
     "iopub.status.idle": "2025-05-24T10:21:55.094825Z",
     "shell.execute_reply": "2025-05-24T10:21:55.094208Z",
     "shell.execute_reply.started": "2025-05-24T10:21:54.811697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_label_counts(dataset):\n",
    "    labels = dataset.targets\n",
    "    unique_labels, counts = torch.unique(labels, return_counts=True)\n",
    "    return dict(zip(unique_labels.tolist(), counts.tolist()))\n",
    "\n",
    "all_label_counts = [get_label_counts(dataset) for dataset in clients_dataset]\n",
    "\n",
    "client_labels = []\n",
    "client_counts = []\n",
    "client_ids = []\n",
    "for i, label_counts in enumerate(all_label_counts):\n",
    "    for label, count in label_counts.items():\n",
    "        client_ids.append(f\"Client {i}\")\n",
    "        client_labels.append(label)\n",
    "        client_counts.append(count)\n",
    "\n",
    "plot_df = pd.DataFrame({'Client': client_ids, 'Label': client_labels, 'Count': client_counts})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Client', y='Count', hue='Label', data=plot_df)\n",
    "plt.title('Label Distribution per Client')\n",
    "plt.xlabel('Client ID')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-24T10:08:02.997Z",
     "iopub.execute_input": "2025-05-24T10:07:24.705977Z",
     "iopub.status.busy": "2025-05-24T10:07:24.705740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 3\n",
    "LEARNING_RATE = 0.01\n",
    "net = BN_CNN(in_channel=1, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def base_client_fn(cid: str):\n",
    "    idx = int(cid)\n",
    "    return BaseClient(cid, net, trainloaders[idx], valloaders[idx], criterion).to_client()\n",
    "\n",
    "current_parameters = ndarrays_to_parameters(get_parameters(net))\n",
    "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.2} if DEVICE == \"cuda\" else {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "            client_fn           = base_client_fn,\n",
    "            num_clients         = NUM_DOMAINS * NUM_CLIENTS_PER_DOMAIN,\n",
    "            config              = fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
    "            strategy            = FedAvg(\n",
    "                learning_rate       = LEARNING_RATE,\n",
    "                exp_name            = 'FL',\n",
    "                algo_name           = 'FedAvg',\n",
    "                net                 = net,\n",
    "                device              = DEVICE,\n",
    "                num_rounds          = NUM_ROUNDS,\n",
    "                num_clients         = NUM_DOMAINS * NUM_CLIENTS_PER_DOMAIN,\n",
    "                current_parameters  = current_parameters,\n",
    "                ),\n",
    "            client_resources     = client_resources\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

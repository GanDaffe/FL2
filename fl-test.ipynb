{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:06.266743Z","iopub.execute_input":"2025-05-24T10:15:06.267097Z","iopub.status.idle":"2025-05-24T10:15:06.641287Z","shell.execute_reply.started":"2025-05-24T10:15:06.267047Z","shell.execute_reply":"2025-05-24T10:15:06.640703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!gdown --id 1-3usuwhbiZUNWiZqUzRIJgnH1AjLCv0K ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:06.642582Z","iopub.execute_input":"2025-05-24T10:15:06.643371Z","iopub.status.idle":"2025-05-24T10:15:17.561159Z","shell.execute_reply.started":"2025-05-24T10:15:06.643349Z","shell.execute_reply":"2025-05-24T10:15:17.559997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!gdown --id 1HvmlbHuwrmRUYJSyP8fKzq8dqKKKPMsv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:17.562227Z","iopub.execute_input":"2025-05-24T10:15:17.562490Z","iopub.status.idle":"2025-05-24T10:15:25.041840Z","shell.execute_reply.started":"2025-05-24T10:15:17.562464Z","shell.execute_reply":"2025-05-24T10:15:25.041122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!gdown --id 1rzQx4mugpWQmJbAQzDCiEgqivSp2u9b-","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:25.044184Z","iopub.execute_input":"2025-05-24T10:15:25.044488Z","iopub.status.idle":"2025-05-24T10:15:30.690996Z","shell.execute_reply.started":"2025-05-24T10:15:25.044462Z","shell.execute_reply":"2025-05-24T10:15:30.690272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom collections import OrderedDict\nfrom typing import List, Dict\nfrom sklearn.model_selection import train_test_split\nimport gc\nimport copy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:58.536982Z","iopub.execute_input":"2025-05-24T10:15:58.537591Z","iopub.status.idle":"2025-05-24T10:15:58.541887Z","shell.execute_reply.started":"2025-05-24T10:15:58.537566Z","shell.execute_reply":"2025-05-24T10:15:58.541222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q flwr[simulation]\n\nimport flwr as fl\nfrom flwr.common import (\n    EvaluateIns,\n    EvaluateRes,\n    FitIns,\n    FitRes,\n    Parameters,\n    Scalar,\n    Status,\n    NDArrays,\n    ndarrays_to_parameters,\n    parameters_to_ndarrays,\n)\nimport os\n\nfrom flwr.server.client_manager import ClientManager\nfrom flwr.server.client_proxy import ClientProxy\nfrom flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\nimport numpy as np\nimport pandas as pd\nfrom typing import List, Tuple, Dict, Union, Optional\nfrom functools import partial, reduce","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:34.969355Z","iopub.execute_input":"2025-05-24T10:15:34.969750Z","iopub.status.idle":"2025-05-24T10:15:46.528582Z","shell.execute_reply.started":"2025-05-24T10:15:34.969730Z","shell.execute_reply":"2025-05-24T10:15:46.527944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct / len(y_pred)) * 100\n    return acc\n\ndef get_parameters(net) -> List[np.ndarray]:\n    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n\ndef set_parameters(net, parameters: List[np.ndarray]):\n    params_dict = zip(net.state_dict().keys(), parameters)\n    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n    net.load_state_dict(state_dict)\n\ndef train(net,\n          trainloader,\n          criterion,\n          optimizer,\n          device,\n          proximal_mu: float = None):\n    net.to(device)\n    net.train()\n    running_loss, running_corrects, tot = 0.0, 0, 0\n\n    global_params = copy.deepcopy(net).parameters()\n\n    for images, labels in trainloader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = net(images)\n\n        loss = criterion(outputs, labels)\n\n        if proximal_mu is not None:\n            proximal_term = sum((local_weights - global_weights).norm(2)\n                                for local_weights, global_weights in zip(net.parameters(), global_params))\n            loss += (proximal_mu / 2) * proximal_term\n\n        loss.backward()\n        optimizer.step()\n\n        predicted = torch.argmax(outputs, dim=1)\n        tot += images.shape[0]\n\n        running_corrects += torch.sum(predicted == labels).item()\n        running_loss += loss.item() * images.shape[0]\n\n        del images, labels, outputs, loss, predicted\n\n    running_loss /= tot\n    accuracy = running_corrects / tot\n\n    del global_params, tot\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    return running_loss, accuracy\n\n\ndef test(net, testloader, device):\n    net.to(device)\n    net.eval()\n    criterion = nn.CrossEntropyLoss()\n    corrects, total_loss, tot = 0, 0.0, 0\n\n    with torch.no_grad():\n        for images, labels in testloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            loss = criterion(outputs, labels)\n\n            predicted = torch.argmax(outputs, dim=1)\n            corrects += torch.sum(predicted == labels).item()\n            total_loss += loss.item() * images.shape[0]\n            tot += images.shape[0]\n\n            del images, labels, outputs, predicted\n\n    total_loss /= tot\n    accuracy = corrects / tot\n\n    del tot\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    return total_loss, accuracy\n\ndef data_processing(df, NUM_FEATURES):\n   y_train = df['Label']\n   flow_id = df['flow_id']\n\n   df = df/255\n\n   X_train = df.drop(['Label', 'flow_id'], axis=1)\n   X_train = X_train.to_numpy()\n\n   X_train = X_train.reshape(-1, 20, NUM_FEATURES)\n   y_train = y_train.to_numpy()\n\n   y_train = y_train.reshape(-1,20)[:,-1]\n   return X_train, y_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:46.529423Z","iopub.execute_input":"2025-05-24T10:15:46.529721Z","iopub.status.idle":"2025-05-24T10:15:46.542667Z","shell.execute_reply.started":"2025-05-24T10:15:46.529697Z","shell.execute_reply":"2025-05-24T10:15:46.541901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch import nn\n\nclass BN_CNN(nn.Module):\n    def __init__(self, in_channel, num_classes=3):\n        super().__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels=in_channel,\n            out_channels=128,\n            kernel_size=5,\n            padding='same')\n\n        self.conv2 = nn.Conv2d(\n            in_channels=128,\n            out_channels=64,\n            kernel_size=5,\n            padding='same')\n\n        self.conv3 = nn.Conv2d(\n            in_channels=64,\n            out_channels=64,\n            kernel_size=3,\n            padding='same')\n\n        self.conv4 = nn.Conv2d(\n            in_channels=64,\n            out_channels=32,\n            kernel_size=3,\n            padding='same')\n\n        self.conv5 = nn.Conv2d(\n            in_channels=32,\n            out_channels=32,\n            kernel_size=3,\n            padding='same')\n\n        self.conv6 = nn.Conv2d(\n            in_channels=32,\n            out_channels=16,\n            kernel_size=3,\n            padding='same')\n\n        self.conv7 = nn.Conv2d(\n            in_channels=16,\n            out_channels=16,\n            kernel_size=3,\n            padding='same')\n\n        self.conv8 = nn.Conv2d(\n            in_channels=16,\n            out_channels=8,\n            kernel_size=3,\n            padding='same')\n\n        self.pool = nn.MaxPool2d(kernel_size=2)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.1)\n        self.bn1 = nn.BatchNorm2d(num_features=64)\n        self.bn2 = nn.BatchNorm2d(num_features=32)\n        self.bn3 = nn.BatchNorm2d(num_features=16)\n        self.bn4 = nn.BatchNorm2d(num_features=8)\n\n        # For input (batch_size, 1, 20, 256), after 4 pooling layers:\n        # Spatial dims: 20x256 -> 10x128 -> 5x64 -> 2x32 -> 1x16\n        # Output of conv8: (batch_size, 8, 1, 16)\n        self.lin1 = nn.Linear(in_features=8 * 1 * 16, out_features=256)\n        self.classification = nn.Linear(256, out_features=num_classes)\n\n    def forward(self, X):\n        X = self.pool(self.bn1(self.relu(self.conv2(self.relu(self.conv1(X))))))\n        X = self.pool(self.bn2(self.relu(self.conv4(self.relu(self.conv3(X))))))\n        X = self.pool(self.bn3(self.relu(self.conv6(self.relu(self.conv5(X))))))\n        X = self.pool(self.bn4(self.relu(self.conv8(self.relu(self.conv7(X))))))\n\n        X = torch.flatten(X, start_dim=1)  # Flatten to (batch_size, 8 * 1 * 16)\n        X = self.lin1(X)\n        X = self.relu(X)\n        X = self.dropout(X)\n        X = self.classification(X)\n\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:46.543491Z","iopub.execute_input":"2025-05-24T10:15:46.543695Z","iopub.status.idle":"2025-05-24T10:15:46.566981Z","shell.execute_reply.started":"2025-05-24T10:15:46.543666Z","shell.execute_reply":"2025-05-24T10:15:46.566302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch import nn\n\nclass CNN(nn.Module):\n    def __init__(self, in_channel, num_classes=3):\n        super().__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels=in_channel,\n            out_channels=128,\n            kernel_size=5,\n            padding='same')\n\n        self.conv2 = nn.Conv2d(\n            in_channels=128,\n            out_channels=64,\n            kernel_size=5,\n            padding='same')\n\n        self.conv3 = nn.Conv2d(\n            in_channels=64,\n            out_channels=64,\n            kernel_size=3,\n            padding='same')\n\n        self.conv4 = nn.Conv2d(\n            in_channels=64,\n            out_channels=32,\n            kernel_size=3,\n            padding='same')\n\n        self.conv5 = nn.Conv2d(\n            in_channels=32,\n            out_channels=32,\n            kernel_size=3,\n            padding='same')\n\n        self.conv6 = nn.Conv2d(\n            in_channels=32,\n            out_channels=16,\n            kernel_size=3,\n            padding='same')\n\n        self.conv7 = nn.Conv2d(\n            in_channels=16,\n            out_channels=16,\n            kernel_size=3,\n            padding='same')\n\n        self.conv8 = nn.Conv2d(\n            in_channels=16,\n            out_channels=8,\n            kernel_size=3,\n            padding='same')\n\n        self.pool = nn.MaxPool2d(kernel_size=2)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.1)\n\n        self.lin1 = nn.Linear(in_features=8 * 1 * 16, out_features=256)\n        self.classification = nn.Linear(256, out_features=num_classes)\n\n    def forward(self, X):\n        X = self.pool(self.relu(self.conv2(self.relu(self.conv1(X)))))\n        X = self.pool(self.relu(self.conv4(self.relu(self.conv3(X)))))\n        X = self.pool(self.relu(self.conv6(self.relu(self.conv5(X)))))\n        X = self.pool(self.relu(self.conv8(self.relu(self.conv7(X)))))\n\n        X = torch.flatten(X, start_dim=1)\n        X = self.lin1(X)\n        X = self.relu(X)\n        X = self.dropout(X)\n        X = self.classification(X)\n\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:46.567685Z","iopub.execute_input":"2025-05-24T10:15:46.567895Z","iopub.status.idle":"2025-05-24T10:15:46.581792Z","shell.execute_reply.started":"2025-05-24T10:15:46.567879Z","shell.execute_reply":"2025-05-24T10:15:46.581049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FedAvg(fl.server.strategy.Strategy):\n\n    def __init__(\n            self,\n            exp_name: str,\n            algo_name: str,\n            net,\n            num_rounds: int,\n            num_clients: int,\n            device,\n            decay_rate: float = 0.995,\n            fraction_fit: float = 1.0,\n            fraction_evaluate: float = 1.0,\n            min_fit_clients: int = 2,\n            min_evaluate_clients: int = 2,\n            min_available_clients: int = 2,\n            learning_rate: float = 0.01,\n            current_parameters: Optional[Parameters] = None):\n\n\n        super().__init__()\n        self.exp_name = exp_name\n        self.algo_name = algo_name\n        self.net = net\n        self.num_rounds = num_rounds\n        self.num_clients = num_clients\n        self.fraction_fit = fraction_fit\n        self.fraction_evaluate = fraction_evaluate\n        self.min_fit_clients = min_fit_clients\n        self.min_evaluate_clients = min_evaluate_clients\n        self.min_available_clients = min_available_clients\n        self.learning_rate = learning_rate\n        self.current_parameters = current_parameters\n        self.device = device\n        self.decay_rate = decay_rate\n\n        self.result = {\"round\": [], \"train_loss\": [], \"train_accuracy\": [], \"test_loss\": [], \"test_accuracy\": []}\n\n\n    def __repr__(self) -> str:\n        return 'FedAvg'\n\n\n    def initialize_parameters(\n        self, client_manager: ClientManager\n    ) -> Optional[Parameters]:\n        \"\"\"Initialize global model parameters.\"\"\"\n        return self.current_parameters\n\n\n    def configure_fit(\n        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n    ) -> List[Tuple[ClientProxy, FitIns]]:\n        \"\"\"Configure the next round of training.\"\"\"\n        sample_size, min_num_clients = self.num_fit_clients(client_manager.num_available())\n        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n\n        config = {\"learning_rate\": self.learning_rate, \"device\": self.device}\n        self.learning_rate *= self.decay_rate\n\n        fit_ins = FitIns(parameters, config)\n\n        fit_configs = [(client, fit_ins) for client in clients]\n        return fit_configs\n\n\n    def aggregate_fit(\n        self,\n        server_round: int,\n        results: List[Tuple[ClientProxy, FitRes]],\n        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n        \"\"\"Aggregate fit results using weighted average.\"\"\"\n        weights_results = [(parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples) for _, fit_res in results]\n        self.current_parameters = ndarrays_to_parameters(aggregate(weights_results))\n        metrics_aggregated = {}\n\n        losses = [fit_res.num_examples * fit_res.metrics[\"loss\"] for _, fit_res in results]\n        corrects = [round(fit_res.num_examples * fit_res.metrics[\"accuracy\"]) for _, fit_res in results]\n        examples = [fit_res.num_examples for _, fit_res in results]\n        loss = sum(losses) / sum(examples)\n        accuracy = sum(corrects) / sum(examples)\n\n        self.result[\"round\"].append(server_round)\n        self.result[\"train_loss\"].append(loss)\n        self.result[\"train_accuracy\"].append(accuracy)\n        print(f\"train_loss: {loss} - train_acc: {accuracy}\")\n\n        return self.current_parameters, metrics_aggregated\n\n\n    def configure_evaluate(\n        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n        \"\"\"Configure the next round of evaluation.\"\"\"\n        \n        sample_size, min_num_clients = self.num_evaluation_clients(client_manager.num_available())\n        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n\n        config = {\"device\": self.device}\n        evaluate_ins = EvaluateIns(parameters, config)\n\n        evaluate_configs = [(client, evaluate_ins) for client in clients]\n        return evaluate_configs\n\n\n    def aggregate_evaluate(\n        self,\n        server_round: int,\n        results: List[Tuple[ClientProxy, EvaluateRes]],\n        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n\n        loss_aggregated = weighted_loss_avg([(evaluate_res.num_examples, evaluate_res.loss) for _, evaluate_res in results])\n        metrics_aggregated = {}\n        \n        corrects = [round(evaluate_res.num_examples * evaluate_res.metrics[\"accuracy\"]) for _, evaluate_res in results]\n        examples = [evaluate_res.num_examples for _, evaluate_res in results]\n        accuracy = sum(corrects) / sum(examples)\n\n        if server_round != 0:\n            self.result[\"test_loss\"].append(loss_aggregated)\n            self.result[\"test_accuracy\"].append(accuracy)\n\n        print(f\"test_loss: {loss_aggregated} - test_acc: {accuracy}\")\n\n        if server_round == self.num_rounds:\n            df = pd.DataFrame(self.result)\n            df.to_csv(f\"result/{self.algo_name}_{self.exp_name}.csv\", index=False)\n\n        return loss_aggregated, metrics_aggregated\n\n  \n    def evaluate(\n        self, server_round: int, parameters: Parameters\n    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n        \"\"\"Evaluate global model parameters using an evaluation function.\"\"\"\n      \n        return None\n\n\n    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n        \"\"\"Return sample size and required number of clients.\"\"\"\n        num_clients = int(num_available_clients * self.fraction_fit)\n        return max(num_clients, self.min_fit_clients), self.min_available_clients\n\n\n    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n        num_clients = int(num_available_clients * self.fraction_evaluate)\n        return max(num_clients, self.min_evaluate_clients), self.min_available_clients","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:46.583935Z","iopub.execute_input":"2025-05-24T10:15:46.584164Z","iopub.status.idle":"2025-05-24T10:15:46.605879Z","shell.execute_reply.started":"2025-05-24T10:15:46.584148Z","shell.execute_reply":"2025-05-24T10:15:46.605268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BaseClient(fl.client.NumPyClient):\n    def __init__(self,\n                 cid,\n                 net,\n                 trainloader,\n                 valloader, \n                 criterion):\n\n        self.cid = cid\n        self.net = net\n        self.trainloader = trainloader\n        self.valloader = valloader\n        self.criterion = criterion\n\n    def get_parameters(self, config):\n        print(config)\n        return get_parameters(self.net)\n\n    def fit(self, parameters, config):\n        set_parameters(self.net, parameters)\n        optimizer = torch.optim.SGD(params=self.net.parameters(), lr=config['learning_rate'])\n        loss, accuracy = train(self.net, self.trainloader, self.criterion, optimizer, device=config['device'])\n        return self.get_parameters(self.net), len(self.trainloader.sampler), {\"loss\": loss, \"accuracy\": accuracy, \"id\": self.cid}\n\n    def evaluate(self, parameters, config):\n        set_parameters(self.net, parameters)\n        loss, accuracy = test(self.net, self.valloader, config['device'])\n        return loss, len(self.valloader.sampler), {\"accuracy\": accuracy}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:46.606508Z","iopub.execute_input":"2025-05-24T10:15:46.606749Z","iopub.status.idle":"2025-05-24T10:15:46.624572Z","shell.execute_reply.started":"2025-05-24T10:15:46.606724Z","shell.execute_reply":"2025-05-24T10:15:46.623856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, input_data, targets, transform=None):\n        self.data = [input_data[i].unsqueeze(0) for i in range(input_data.size(0))]\n        self.targets = targets\n        self.classes = torch.unique(targets).tolist()\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.targets[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:46.625292Z","iopub.execute_input":"2025-05-24T10:15:46.625456Z","iopub.status.idle":"2025-05-24T10:15:46.641176Z","shell.execute_reply.started":"2025-05-24T10:15:46.625443Z","shell.execute_reply":"2025-05-24T10:15:46.640518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"c1_data = pd.read_feather('/kaggle/working/Domain 1.feather')\nc2_data = pd.read_feather('/kaggle/working/Domain 2.feather')\nc3_data = pd.read_feather('/kaggle/working/Domain 3.feather')\n\ndata_full = [c1_data, c2_data , c3_data]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:15:46.641802Z","iopub.execute_input":"2025-05-24T10:15:46.642086Z","iopub.status.idle":"2025-05-24T10:15:47.550863Z","shell.execute_reply.started":"2025-05-24T10:15:46.642043Z","shell.execute_reply":"2025-05-24T10:15:47.550303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport numpy as np\nimport random\n\ndef set_seed(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed_value)\n    print(f\"Seeds set to {seed_value}\")\n\ndef domain_partition(X, y, num_clients):\n    num_classes = np.unique(y).shape[0]\n    class_indices = [[] for _ in range(num_classes)]\n\n    for i, lab in enumerate(y):\n        class_indices[lab].append(i)\n\n    client_indices = [[] for _ in range(num_clients)]\n\n    for c in range(num_classes):\n        proportions = np.random.dirichlet(np.ones(num_clients) * 5)\n        indices = np.array(class_indices[c])\n        np.random.shuffle(indices)\n\n        proportions = (np.cumsum(proportions) * len(indices)).astype(int)[:-1]\n        split_indices = np.split(indices, proportions)\n\n        for i, idx in enumerate(split_indices):\n            client_indices[i].extend(idx.tolist())\n\n    client_data = [(torch.from_numpy(X[client_idx]), torch.from_numpy(y[client_idx])) for client_idx in client_indices]\n\n    return client_data\n\ndef get_clients_dataset(full_domain_data, num_domains, num_clients_per_domain):   \n    set_seed(42)\n    all_data = [] \n\n    for domain in full_domain_data:\n        all_data.append(data_processing(domain, 256))\n\n    domain_clients = []\n    for data, label in all_data:  \n        domain_clients.extend(domain_partition(data, label, num_clients_per_domain))\n\n    for i in range(len(domain_clients)):\n        domain_clients[i] = CustomDataset(domain_clients[i][0], domain_clients[i][1])\n    return domain_clients\n    \n\nNUM_DOMAINS = 3\nNUM_CLIENTS_PER_DOMAIN = 3\nBATCH_SIZE = 32\nRANDOM_STATE = 42\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nclients_dataset = get_clients_dataset(data_full, NUM_DOMAINS, NUM_CLIENTS_PER_DOMAIN)\n\ntrain_set, validation_set = [], []\n\nfor i in range(len(clients_dataset)):\n    train, val = train_test_split(clients_dataset[i], test_size=0.2, random_state=RANDOM_STATE)\n    train_set.append(train)\n    validation_set.append(val)\n\ntrainloaders = [DataLoader(train_set[i], batch_size=BATCH_SIZE) for i in range(len(train_set))]\nvalloaders = [DataLoader(validation_set[i], batch_size=BATCH_SIZE) for i in range(len(validation_set))]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:21:53.103832Z","iopub.execute_input":"2025-05-24T10:21:53.104491Z","iopub.status.idle":"2025-05-24T10:21:54.366906Z","shell.execute_reply.started":"2025-05-24T10:21:53.104464Z","shell.execute_reply":"2025-05-24T10:21:54.366112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_label_counts(dataset):\n    labels = dataset.targets\n    unique_labels, counts = torch.unique(labels, return_counts=True)\n    return dict(zip(unique_labels.tolist(), counts.tolist()))\n\nall_label_counts = [get_label_counts(dataset) for dataset in clients_dataset]\n\nclient_labels = []\nclient_counts = []\nclient_ids = []\nfor i, label_counts in enumerate(all_label_counts):\n    for label, count in label_counts.items():\n        client_ids.append(f\"Client {i}\")\n        client_labels.append(label)\n        client_counts.append(count)\n\nplot_df = pd.DataFrame({'Client': client_ids, 'Label': client_labels, 'Count': client_counts})\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x='Client', y='Count', hue='Label', data=plot_df)\nplt.title('Label Distribution per Client')\nplt.xlabel('Client ID')\nplt.ylabel('Number of Samples')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:21:54.811208Z","iopub.execute_input":"2025-05-24T10:21:54.811718Z","iopub.status.idle":"2025-05-24T10:21:55.094825Z","shell.execute_reply.started":"2025-05-24T10:21:54.811697Z","shell.execute_reply":"2025-05-24T10:21:55.094208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_ROUNDS = 3\nLEARNING_RATE = 0.01\nnet = BN_CNN(in_channel=1, num_classes=3)\ncriterion = nn.CrossEntropyLoss()\ndef base_client_fn(cid: str):\n    idx = int(cid)\n    return BaseClient(cid, net, trainloaders[idx], valloaders[idx], criterion).to_client()\n\ncurrent_parameters = ndarrays_to_parameters(get_parameters(net))\nclient_resources = {\"num_cpus\": 1, \"num_gpus\": 0.2} if DEVICE == \"cuda\" else {\"num_cpus\": 1, \"num_gpus\": 0.0}\n\nfl.simulation.start_simulation(\n            client_fn           = base_client_fn,\n            num_clients         = NUM_DOMAINS * NUM_CLIENTS_PER_DOMAIN,\n            config              = fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n            strategy            = FedAvg(\n                learning_rate       = LEARNING_RATE,\n                exp_name            = 'FL',\n                algo_name           = 'FedAvg',\n                net                 = net,\n                device              = DEVICE,\n                num_rounds          = NUM_ROUNDS,\n                num_clients         = NUM_DOMAINS * NUM_CLIENTS_PER_DOMAIN,\n                current_parameters  = current_parameters,\n                ),\n            client_resources     = client_resources\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:07:24.705740Z","iopub.execute_input":"2025-05-24T10:07:24.705977Z","execution_failed":"2025-05-24T10:08:02.997Z"}},"outputs":[],"execution_count":null}]}